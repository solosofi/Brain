{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GODBRAIN Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the GODBRAIN system for interactive reasoning and question answering. GODBRAIN combines symbolic reasoning with a knowledge graph and metacognitive abilities to provide answers with explanations and confidence scores.\n",
    "\n",
    "## Components of GODBRAIN:\n",
    "\n",
    "1. **Perception Layer** (TextParser): Processes natural language input\n",
    "2. **Logical Core** (ReasoningEngine): Performs symbolic reasoning using Prolog\n",
    "3. **World Model** (KnowledgeGraph): Maintains a graph-based representation of knowledge\n",
    "4. **Meta-Cognition Unit** (ConfidenceEvaluator): Evaluates confidence in answers and can revise them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Initialization\n",
    "\n",
    "First, let's import the necessary modules and initialize the GODBRAIN system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path so we can import the GODBRAIN modules\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "# Import the GODBRAIN system\n",
    "from src.godbrain import GODBRAIN\n",
    "\n",
    "# Initialize the GODBRAIN system with a confidence threshold of 0.7\n",
    "brain = GODBRAIN(confidence_threshold=0.7)\n",
    "\n",
    "print(\"GODBRAIN system initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Knowledge Base\n",
    "\n",
    "The GODBRAIN system is initialized with some basic knowledge about philosophers. Let's examine what it knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the facts and rules in the logical core\n",
    "print(\"Facts and rules in the logical core:\n\")\n",
    "for item in brain.logical_core.knowledge_base:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "print(\"\nEntities in the world model:\n\")\n",
    "for entity in brain.world_model.get_all_entities():\n",
    "    print(f\"  {entity}: {brain.world_model.entity_attributes.get(entity, {})}\")\n",
    "\n",
    "print(\"\nRelationships in the world model:\n\")\n",
    "for subject, predicate, object_ in brain.world_model.get_all_relationships():\n",
    "    print(f\"  {subject} {predicate} {object_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a Simple Query\n",
    "\n",
    "Let's try processing a simple query to see how GODBRAIN works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a simple query\n",
    "query = \"Is Socrates mortal?\"\n",
    "result = brain.process_input(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "print(\"Explanation:\n{}\".format(result['explanation']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Knowledge\n",
    "\n",
    "We can extend GODBRAIN's knowledge by adding new facts and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new facts to the logical core\n",
    "brain.logical_core.add_fact(\"human(pythagoras).\")\n",
    "brain.logical_core.add_fact(\"teacher(pythagoras, empedocles).\")\n",
    "brain.logical_core.add_fact(\"human(empedocles).\")\n",
    "\n",
    "# Add corresponding entities and relationships to the world model\n",
    "brain.world_model.add_entity('pythagoras', {'type': 'person'})\n",
    "brain.world_model.add_entity('empedocles', {'type': 'person'})\n",
    "\n",
    "brain.world_model.add_relationship('pythagoras', 'is_a', 'human')\n",
    "brain.world_model.add_relationship('empedocles', 'is_a', 'human')\n",
    "brain.world_model.add_relationship('pythagoras', 'teacher_of', 'empedocles')\n",
    "brain.world_model.add_relationship('pythagoras', 'is_a', 'philosopher')\n",
    "\n",
    "print(\"New knowledge added successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the New Knowledge\n",
    "\n",
    "Let's test GODBRAIN with queries about the new knowledge we just added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries with the new knowledge\n",
    "queries = [\n",
    "    \"Is Pythagoras mortal?\",\n",
    "    \"Is Pythagoras a philosopher?\",\n",
    "    \"Who is the teacher of Empedocles?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    result = brain.process_input(query)\n",
    "    print(f\"\nQuery: {query}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "    print(\"Explanation:\n{}\".format(result['explanation']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Chat Interface\n",
    "\n",
    "Now let's create an interactive chat interface to interact with GODBRAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create the chat history and input widgets\n",
    "chat_history = widgets.HTML(\n",
    "    value='<div style=\"height: 400px; overflow-y: auto; background-color: #f5f5f5; padding: 10px; border-radius: 5px;\"></div>',\n",
    "    layout=widgets.Layout(width='100%', height='400px')\n",
    ")\n",
    "\n",
    "user_input = widgets.Text(\n",
    "    placeholder='Ask GODBRAIN a question...',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "send_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='19%')\n",
    ")\n",
    "\n",
    "input_box = widgets.HBox([user_input, send_button])\n",
    "\n",
    "# Function to update the chat history\n",
    "def update_chat(sender=None):\n",
    "    query = user_input.value.strip()\n",
    "    if not query:\n",
    "        return\n",
    "    \n",
    "    # Clear the input box\n",
    "    user_input.value = ''\n",
    "    \n",
    "    # Get the current chat history\n",
    "    current_history = chat_history.value\n",
    "    \n",
    "    # Add the user's query to the chat history\n",
    "    current_history = current_history.replace('</div>', f'<p><strong>You:</strong> {query}</p></div>')\n",
    "    chat_history.value = current_history\n",
    "    \n",
    "    # Process the query with GODBRAIN\n",
    "    result = brain.process_input(query)\n",
    "    \n",
    "    # Format the response\n",
    "    answer = result['answer']\n",
    "    confidence = result['confidence']\n",
    "    explanation = result['explanation'].replace('\n', '<br>')\n",
    "    \n",
    "    # Add the response to the chat history\n",
    "    confidence_color = 'green' if confidence >= 0.7 else 'orange' if confidence >= 0.4 else 'red'\n",
    "    response_html = f'''\n",
    "    <p><strong>GODBRAIN:</strong> {answer}</p>\n",
    "    <p><small style=\"color: {confidence_color};\">Confidence: {confidence:.2f}</small></p>\n",
    "    <p><small><em>Explanation:</em><br>{explanation}</small></p>\n",
    "    <hr>\n",
    "    '''\n",
    "    \n",
    "    current_history = chat_history.value\n",
    "    current_history = current_history.replace('</div>', f'{response_html}</div>')\n",
    "    chat_history.value = current_history\n",
    "\n",
    "# Connect the button and input box to the update_chat function\n",
    "send_button.on_click(update_chat)\n",
    "user_input.on_submit(update_chat)\n",
    "\n",
    "# Display the chat interface\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML('<h3>Chat with GODBRAIN</h3>'),\n",
    "    chat_history,\n",
    "    input_box\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Queries\n",
    "\n",
    "Here are some example queries you can try with GODBRAIN:\n",
    "\n",
    "1. Is Socrates mortal?\n",
    "2. Is Plato a philosopher?\n",
    "3. Who is the teacher of Plato?\n",
    "4. Is Empedocles a student of Pythagoras?\n",
    "5. What is a human?\n",
    "\n",
    "Feel free to try your own queries as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Knowledge Graph\n",
    "\n",
    "Let's visualize the knowledge graph to see the relationships between entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the knowledge graph\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Get the graph from the world model\n",
    "G = brain.world_model.graph\n",
    "\n",
    "# Create a figure with a larger size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define node colors based on entity type\n",
    "node_colors = []\n",
    "for node in G.nodes():\n",
    "    entity_type = brain.world_model.entity_attributes.get(node, {}).get('type', 'unknown')\n",
    "    if entity_type == 'person':\n",
    "        node_colors.append('lightblue')\n",
    "    elif entity_type == 'class':\n",
    "        node_colors.append('lightgreen')\n",
    "    else:\n",
    "        node_colors.append('lightgray')\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G, seed=42)  # Seed for reproducible layout\n",
    "nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=2000, font_size=10, font_weight='bold')\n",
    "\n",
    "# Draw edge labels\n",
    "edge_labels = {}\n",
    "for u, v, data in G.edges(data=True):\n",
    "    edge_labels[(u, v)] = data.get('predicate', '')\n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "plt.title('GODBRAIN Knowledge Graph')\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the GODBRAIN system for interactive reasoning and question answering. We've seen how the system combines symbolic reasoning with a knowledge graph and metacognitive abilities to provide answers with explanations and confidence scores.\n",
    "\n",
    "The GODBRAIN architecture consists of four main components:\n",
    "\n",
    "1. **Perception Layer**: Processes natural language input\n",
    "2. **Logical Core**: Performs symbolic reasoning using Prolog\n",
    "3. **World Model**: Maintains a graph-based representation of knowledge\n",
    "4. **Meta-Cognition Unit**: Evaluates confidence in answers and can revise them\n",
    "\n",
    "These components work together to create a system that can reason about the world and answer questions with explanations and confidence scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
